# Cursor Agent Rules & Best Practices

## Project: Satoshi Poster Binary Extraction

---

## ğŸ¨ Cursor Agent Mission
- **Primary Focus:** Code editing, interactive parameter tuning, rapid iteration, and code organization to maximize extraction pipeline quality and adaptability.
- **Goal:** Enable fast, reproducible improvements to extraction accuracy through code-level changes and interactive development.

---

## ğŸ‘¤ Responsibilities
1. **Parameter Tuning**
   - Interactively adjust grid, threshold, and extraction parameters in code (e.g., `cfg.yaml`, pipeline scripts).
   - Use code-driven overlays and debug outputs to surface ambiguous/problematic regions for review.
   - Log parameter changes and their effects in markdown or status files.
2. **Code Refinement**
   - Refactor and optimize extraction algorithms for clarity, maintainability, and performance.
   - Implement and test new features or improvements rapidly.
3. **Debugging**
   - Identify and fix issues found during extraction runs.
   - Use automated tests and debug outputs to validate fixes.
4. **Code Organization**
   - Maintain clear, modular code structure.
   - Use agent-prefixed file names for new tools/utilities (e.g., `cursor_grid_tools.py`).

---

## ğŸ¤ Collaboration & Human-in-the-Loop
- **Visual/manual validation is not performed by the Cursor agent.**
- The Cursor agent builds tools and outputs (e.g., overlays, debug images, flagged regions) to assist human collaborators or other agents in performing visual/manual review.
- Coordinate with Claude and Codex agents by:
  - Updating `project_status.json` after major changes.
  - Sharing findings and code changes in markdown reports.
  - Clearly commenting on all code/config changes.

---

## ğŸ“‹ Best Practices
- **Iterate quickly:** Make small, testable changes and validate results.
- **Document rationale:** Log why parameter/code changes were made.
- **Prioritize clarity:** Code and outputs should be easy to interpret and use.
- **Collaborate:** Communicate regularly with other agents and human reviewers.
- **Be honest about limitations:** Clearly flag any uncertainties or ambiguous results for human review.

---

## ğŸš¦ Success Criteria
- Extraction pipeline is easy to tune and iterate on.
- Parameter/code changes are well-documented and reproducible.
- Debug outputs and overlays clearly surface issues for human/agent review.
- Codebase remains organized, modular, and maintainable.

---

*Last updated: 2025-07-16* 